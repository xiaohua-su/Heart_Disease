{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Predicting Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Author: Xiaohua Su\n",
    "\n",
    "Date: May 17th, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As of 2020, heart disease is the leading cause of death in the US, with the disease claiming close to 700,000 that year. It is the leading cause of death regardless of gender and for most race/ethnicity. This disease can lead to early death in individuals, increase medicial visits and a lost of productivity in our economy. As such, it is important to try to address this. My project aims to help build a predictive model for heart disease. By being able to predict whether a patient has heart disease or not, this can be used in hospital to flag doctors to discuss way to manage this disease and prevent early death and potentially slow/mitigate the disease progression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With how prevalent heart disease is in the nation, it is important for doctors to discuss with their patients about early prevention. In order to do this, doctors would need to know more about a patient’s history in order to diagnose them with having heart disease, potentially requiring blood work in addition. Getting the results from the blood work usually happens after the patient’s is already out of the doctor’s office. Calls will then be made to discuss these results and potential follow up appointments will be made. \n",
    "\n",
    "Our model aims to predict whether a patient, who comes into a doctor’s office/hospital, has heart disease. By being able to predict if the patient has heart disease or not, we can then flag this patient for the doctor electronically. Instead of having to waiting for a phone call for a discussion on, that may not be between the patient and doctor, conversation between the doctor and patient about managing heart disease can begin. This flagging can help start the conversation between the doctor and patient about early prevention steps that can be made and can help lead the doctor in asking certain questions for further verification and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data was taken from the [CDC's 2020 Behavorial Risk Factor Surveillance System](https://www.cdc.gov/brfss/annual_data/annual_2020.html) (BRFSS). Due to how large the data is, this data was not uploaded to the github but can be found where the data was taken underneath the data files section.\n",
    "\n",
    "It is a survey data performed between 2020 to 2021 from the CDC to monitor people's health-behavior, chronic health conditions, and use of services to help manage their disease. The data contains information of the individual such as `race` and `gender` that we will not use to avoid these biases in our models. A new column was created as the data does not specifically have a column called heart disease but instead has two two columns called `cvdinfr4` and `cvdcrhd4` that corresponded with whether the individual was ever told/diagnose with having a heart attack and told that they had coronary heart disease. Both questions, get at the issue of heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***The neural network modeling was performed with tensorflow. In order for it to work properly you must have at least tensorflow 2.5 and above. Please use the provided yml file to create the enviroment properly on a windows as it has tensorflow version 2.8.0 within it. Unfortunately, I do not have access to a Mac as such a Mac yml file is not provide. Not only that but there is some known issue with more recent versions of tensorflow with the M1 chips as such I highly recommend running this notebook on a windows or a cloud base service such as google colab.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, Normalization, IntegerLookup, CategoryEncoding\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import  keras\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras import Model\n",
    "from get_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heart = pd.read_csv('./Data/heart_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>state</th>\n",
       "      <th>general_health</th>\n",
       "      <th>physical_health</th>\n",
       "      <th>mental_health</th>\n",
       "      <th>health_insurance</th>\n",
       "      <th>health_care_doctors</th>\n",
       "      <th>no_doc_bc_cost</th>\n",
       "      <th>last_checkup</th>\n",
       "      <th>excercise_30</th>\n",
       "      <th>...</th>\n",
       "      <th>income_level</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>height_m</th>\n",
       "      <th>difficulty_walking</th>\n",
       "      <th>smoke100_lifetime</th>\n",
       "      <th>smokeless_tobacco_products</th>\n",
       "      <th>alcohol_consumption_30</th>\n",
       "      <th>high_risk_situations</th>\n",
       "      <th>ecigaret</th>\n",
       "      <th>heart_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>163.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397142</th>\n",
       "      <td>401953</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397143</th>\n",
       "      <td>401954</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397144</th>\n",
       "      <td>401955</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397145</th>\n",
       "      <td>401956</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397146</th>\n",
       "      <td>401957</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397147 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  state  general_health  physical_health  mental_health  \\\n",
       "0                0    1.0             2.0              3.0           30.0   \n",
       "1                1    1.0             3.0              0.0            0.0   \n",
       "2                2    1.0             3.0              0.0            0.0   \n",
       "3                3    1.0             1.0              0.0            0.0   \n",
       "4                4    1.0             2.0              0.0            0.0   \n",
       "...            ...    ...             ...              ...            ...   \n",
       "397142      401953   72.0             3.0              0.0            0.0   \n",
       "397143      401954   72.0             3.0              0.0            0.0   \n",
       "397144      401955   72.0             3.0              0.0            0.0   \n",
       "397145      401956   72.0             3.0              0.0            0.0   \n",
       "397146      401957   72.0             3.0              2.0            7.0   \n",
       "\n",
       "        health_insurance  health_care_doctors  no_doc_bc_cost  last_checkup  \\\n",
       "0                    2.0                  3.0             1.0           4.0   \n",
       "1                    1.0                  1.0             1.0           1.0   \n",
       "2                    1.0                  1.0             2.0           1.0   \n",
       "3                    1.0                  3.0             2.0           2.0   \n",
       "4                    1.0                  1.0             2.0           1.0   \n",
       "...                  ...                  ...             ...           ...   \n",
       "397142               2.0                  1.0             2.0           2.0   \n",
       "397143               1.0                  1.0             2.0           3.0   \n",
       "397144               1.0                  1.0             2.0           2.0   \n",
       "397145               1.0                  1.0             2.0           1.0   \n",
       "397146               1.0                  1.0             2.0           1.0   \n",
       "\n",
       "        excercise_30  ...  income_level  weight_kg  height_m  \\\n",
       "0                1.0  ...           1.0       48.0     170.0   \n",
       "1                1.0  ...           NaN        NaN     163.0   \n",
       "2                1.0  ...           7.0        NaN     173.0   \n",
       "3                2.0  ...           NaN        NaN       NaN   \n",
       "4                1.0  ...           NaN       57.0     168.0   \n",
       "...              ...  ...           ...        ...       ...   \n",
       "397142           1.0  ...           NaN       55.0     150.0   \n",
       "397143           2.0  ...           4.0       76.0     152.0   \n",
       "397144           1.0  ...           1.0       72.0     124.0   \n",
       "397145           1.0  ...           NaN       80.0     173.0   \n",
       "397146           2.0  ...           5.0       90.0     170.0   \n",
       "\n",
       "        difficulty_walking  smoke100_lifetime  smokeless_tobacco_products  \\\n",
       "0                      2.0                1.0                         3.0   \n",
       "1                      2.0                NaN                         NaN   \n",
       "2                      2.0                2.0                         3.0   \n",
       "3                      2.0                2.0                         3.0   \n",
       "4                      2.0                2.0                         3.0   \n",
       "...                    ...                ...                         ...   \n",
       "397142                 2.0                2.0                         3.0   \n",
       "397143                 2.0                2.0                         3.0   \n",
       "397144                 2.0                2.0                         3.0   \n",
       "397145                 2.0                7.0                         3.0   \n",
       "397146                 2.0                2.0                         3.0   \n",
       "\n",
       "        alcohol_consumption_30  high_risk_situations  ecigaret  heart_disease  \n",
       "0                          0.0                   2.0       1.0            0.0  \n",
       "1                          NaN                   NaN       NaN            0.0  \n",
       "2                          0.0                   2.0       2.0            0.0  \n",
       "3                          0.0                   2.0       2.0            0.0  \n",
       "4                          0.0                   2.0       2.0            0.0  \n",
       "...                        ...                   ...       ...            ...  \n",
       "397142                     0.0                   2.0       NaN            0.0  \n",
       "397143                     0.0                   2.0       NaN            0.0  \n",
       "397144                     0.0                   2.0       NaN            0.0  \n",
       "397145                     4.0                   2.0       NaN            0.0  \n",
       "397146                     0.0                   2.0       NaN            0.0  \n",
       "\n",
       "[397147 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heart.drop(columns = 'Unnamed: 0', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heart.drop(columns = ['education_lvl', 'income_level', 'employment_status', 'rent_own', 'health_care_doctors','no_doc_bc_cost', 'smokeless_tobacco_products', 'high_risk_situations', 'ecigaret', 'state'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general_health            float64\n",
       "physical_health           float64\n",
       "mental_health             float64\n",
       "health_insurance          float64\n",
       "last_checkup              float64\n",
       "excercise_30              float64\n",
       "sleep                     float64\n",
       "stroke                    float64\n",
       "asthma                    float64\n",
       "skin_cancer               float64\n",
       "other_cancer              float64\n",
       "copd_type_issue           float64\n",
       "arthritis_anyform         float64\n",
       "depressive_disorder       float64\n",
       "kidney_disease            float64\n",
       "diabetes                  float64\n",
       "weight_kg                 float64\n",
       "height_m                  float64\n",
       "difficulty_walking        float64\n",
       "smoke100_lifetime         float64\n",
       "alcohol_consumption_30    float64\n",
       "heart_disease             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "heart = heart.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general_health              1\n",
       "physical_health            32\n",
       "mental_health              15\n",
       "health_insurance            2\n",
       "last_checkup                6\n",
       "excercise_30                0\n",
       "sleep                      19\n",
       "stroke                      2\n",
       "asthma                      2\n",
       "skin_cancer                 2\n",
       "other_cancer                2\n",
       "copd_type_issue             5\n",
       "arthritis_anyform           3\n",
       "depressive_disorder         4\n",
       "kidney_disease              8\n",
       "diabetes                    1\n",
       "weight_kg                 108\n",
       "height_m                   39\n",
       "difficulty_walking         39\n",
       "smoke100_lifetime          38\n",
       "alcohol_consumption_30     50\n",
       "heart_disease               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# heart.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = heart.drop(columns='heart_disease')\n",
    "y = heart.heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_original, X_test, y_train_original, y_test = train_test_split(X,y, stratify=y ,random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_original,y_train_original, stratify=y_train_original, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#creating list of columns names that needs to be either scaled or OHE\n",
    "continous = ['physical_health', 'mental_health', 'last_checkup' , 'excercise_30', 'sleep', 'weight_kg',\n",
    "             'height_m', 'alcohol_consumption_30']\n",
    "\n",
    "categorical = list(X_train.columns.drop(continous))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline(steps=[('cat_impute', IterativeImputer(estimator = RandomForestClassifier(),\\\n",
    "                                                           random_state=42, max_iter = 5))])\n",
    "scale_pipe = Pipeline(steps=[('scale_impute', IterativeImputer(random_state=42))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ct = ColumnTransformer(transformers=[('scale', scale_pipe, continous), ('cat', cat_pipe, categorical)]).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def df_imputation_transformer(dataframe):\n",
    "    dataframe= ct.transform(dataframe)\n",
    "    dataframe = pd.DataFrame(dataframe, columns=get_feature_names(ct))\n",
    "    dataframe.columns = [name.strip().replace(\"cat__\",'').replace(\"scale__\", '') for name in dataframe.columns]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiaoh\\Documents\\Flatiron\\neural_network_portion\\get_features.py:36: UserWarning: Transformer scale_impute (type IterativeImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n",
      "C:\\Users\\xiaoh\\Documents\\Flatiron\\neural_network_portion\\get_features.py:36: UserWarning: Transformer cat_impute (type IterativeImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n",
      "C:\\Users\\xiaoh\\Documents\\Flatiron\\neural_network_portion\\get_features.py:36: UserWarning: Transformer scale_impute (type IterativeImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n",
      "C:\\Users\\xiaoh\\Documents\\Flatiron\\neural_network_portion\\get_features.py:36: UserWarning: Transformer cat_impute (type IterativeImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n",
      "C:\\Users\\xiaoh\\Documents\\Flatiron\\neural_network_portion\\get_features.py:36: UserWarning: Transformer scale_impute (type IterativeImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n",
      "C:\\Users\\xiaoh\\Documents\\Flatiron\\neural_network_portion\\get_features.py:36: UserWarning: Transformer cat_impute (type IterativeImputer) does not provide get_feature_names. Will return input column names if available\n",
      "  warnings.warn(\"Transformer %s (type %s) does not \"\n"
     ]
    }
   ],
   "source": [
    "train = df_imputation_transformer(X_train)\n",
    "val = df_imputation_transformer(X_val)\n",
    "test = df_imputation_transformer(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 562 entries, 0 to 561\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   physical_health         562 non-null    float64\n",
      " 1   mental_health           562 non-null    float64\n",
      " 2   last_checkup            562 non-null    float64\n",
      " 3   excercise_30            562 non-null    float64\n",
      " 4   sleep                   562 non-null    float64\n",
      " 5   weight_kg               562 non-null    float64\n",
      " 6   height_m                562 non-null    float64\n",
      " 7   alcohol_consumption_30  562 non-null    float64\n",
      " 8   general_health          562 non-null    float64\n",
      " 9   health_insurance        562 non-null    float64\n",
      " 10  stroke                  562 non-null    float64\n",
      " 11  asthma                  562 non-null    float64\n",
      " 12  skin_cancer             562 non-null    float64\n",
      " 13  other_cancer            562 non-null    float64\n",
      " 14  copd_type_issue         562 non-null    float64\n",
      " 15  arthritis_anyform       562 non-null    float64\n",
      " 16  depressive_disorder     562 non-null    float64\n",
      " 17  kidney_disease          562 non-null    float64\n",
      " 18  diabetes                562 non-null    float64\n",
      " 19  difficulty_walking      562 non-null    float64\n",
      " 20  smoke100_lifetime       562 non-null    float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 92.3 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>physical_health</th>\n",
       "      <th>mental_health</th>\n",
       "      <th>last_checkup</th>\n",
       "      <th>excercise_30</th>\n",
       "      <th>sleep</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>height_m</th>\n",
       "      <th>alcohol_consumption_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>81.496091</td>\n",
       "      <td>167.518221</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>562 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     physical_health  mental_health  last_checkup  excercise_30  sleep  \\\n",
       "0                0.0            0.0           2.0           2.0    6.0   \n",
       "1                2.0            0.0           1.0           1.0    7.0   \n",
       "2                0.0           30.0           1.0           2.0    5.0   \n",
       "3                0.0            0.0           1.0           1.0    8.0   \n",
       "4                0.0            0.0           1.0           1.0    7.0   \n",
       "..               ...            ...           ...           ...    ...   \n",
       "557              0.0            5.0           2.0           1.0    6.0   \n",
       "558              0.0            0.0           2.0           1.0    6.0   \n",
       "559              0.0            0.0           1.0           2.0    8.0   \n",
       "560              0.0            0.0           1.0           1.0    7.0   \n",
       "561              3.0            0.0           1.0           1.0    8.0   \n",
       "\n",
       "      weight_kg    height_m  alcohol_consumption_30  \n",
       "0     81.496091  167.518221                     0.0  \n",
       "1     91.000000  183.000000                     0.0  \n",
       "2     68.000000  152.000000                     0.0  \n",
       "3     73.000000  165.000000                     0.0  \n",
       "4    100.000000  170.000000                     0.0  \n",
       "..          ...         ...                     ...  \n",
       "557   73.000000  155.000000                     0.0  \n",
       "558   75.000000  175.000000                     0.0  \n",
       "559   95.000000  168.000000                     0.0  \n",
       "560   71.000000  170.000000                     0.0  \n",
       "561   68.000000  168.000000                     9.0  \n",
       "\n",
       "[562 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continous_train = train[continous]\n",
    "continous_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "continous_val = val[continous]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(continous_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    BinaryAccuracy(name='accuracy'),\n",
    "    Precision(name='precision'),\n",
    "    Recall(name='recall'),\n",
    "    AUC(name='auc'),\n",
    "    AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_basic_model():\n",
    "    model = tf.keras.Sequential([normalizer,\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=[tf.keras.metrics.Recall()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2876, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3145, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-56-e6de44335bc2>\", line 2, in <module>\n      model.fit(continous_train, y_train, validation_data= (continous_val, y_val) ,epochs=15, batch_size=50)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\metrics.py\", line 1533, in update_state\n      return metrics_utils.update_confusion_matrix_variables(\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 602, in update_confusion_matrix_variables\n      tf.compat.v1.assert_greater_equal(\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\nassertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_11/dense_35/BiasAdd:0) = ] [[-0.0859924629][-0.39077425][0.116408363]...] [y (Cast_2/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_15813]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-56-e6de44335bc2>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_basic_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcontinous_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mcontinous_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_val\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m,\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m15\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Graph execution error:\n\nDetected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n      app.start()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n      self.do_execute(\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2876, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2922, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3145, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3337, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3417, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-56-e6de44335bc2>\", line 2, in <module>\n      model.fit(continous_train, y_train, validation_data= (continous_val, y_val) ,epochs=15, batch_size=50)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\metrics.py\", line 1533, in update_state\n      return metrics_utils.update_confusion_matrix_variables(\n    File \"C:\\Users\\xiaoh\\anaconda3\\envs\\learn-env\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 602, in update_confusion_matrix_variables\n      tf.compat.v1.assert_greater_equal(\nNode: 'assert_greater_equal/Assert/AssertGuard/Assert'\nassertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (sequential_11/dense_35/BiasAdd:0) = ] [[-0.0859924629][-0.39077425][0.116408363]...] [y (Cast_2/x:0) = ] [0]\n\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_15813]"
     ]
    }
   ],
   "source": [
    "model = get_basic_model()\n",
    "model.fit(continous_train, y_train, validation_data= (continous_val, y_val) ,epochs=15, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The next step for this project would be to further refine our target. This projects only looks at heart attack and Cornary Artery Disease. These two conditions are some of the conditions that fall under the heart disease. Heart disease encompasses other conditions such as high blood pressure, congenitial heart disease etc., it's not just CAD and heart attacks as such we would have to refine the questions being asked to individual. \n",
    "\n",
    "Not only that but more time to refine our model. Due to computational limitation of my system and the computational time, I am not able to perform as much gridsearches to fine-tune the model even further. Not only that but we can refine our model on data from patients' information form and the diagnoses given by the doctor to help improve the flagging of indivduals with such a condition that way their primary doctor know to discuss this with the patient.\n",
    "\n",
    "Build a better app. The app created was for demonstrated purposes. Preferabily, the app would be further improve to take in a picture of the form filled out by the patient and would be able to pick out the data from the image and input it into our model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}